{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efff4bec",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039879f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os, math, json, cv2, numpy as np, pandas as pd, tensorflow as tf\n",
    "tf.keras.mixed_precision.set_global_policy('float32')\n",
    "from tensorflow.keras import layers, models, losses, optimizers, callbacks, metrics\n",
    "from tensorflow.keras.applications import efficientnet_v2\n",
    "import matplotlib.pyplot as plt, matplotlib.patches as patches\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4fbe7",
   "metadata": {},
   "source": [
    "# Global Parameters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224, 3)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf58986c",
   "metadata": {},
   "source": [
    "# DataFrame creation extracting infos from the attached text files\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ea17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/Users/debanjan_5402/Downloads/archive/CUB_200_2011/CUB_200_2011\"\n",
    "CLASS_TXT = f\"{BASE}/classes.txt\"; IMG_TXT = f\"{BASE}/images.txt\"\n",
    "SPLIT_TXT = f\"{BASE}/train_test_split.txt\"; LABEL_TXT = f\"{BASE}/image_class_labels.txt\"\n",
    "BBOX_TXT = f\"{BASE}/bounding_boxes.txt\"; IMG_DIR = f\"{BASE}/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c920240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = pd.read_csv(CLASS_TXT, sep=' ', header=None, names=['class', 'class_name'], dtype={'class': 'int32', 'class_name': 'str'})\n",
    "class_df['class_name'] = class_df['class_name'].str.replace(r'^\\d{3}\\.', '', regex=True)\n",
    "class_df['class'] -= 1\n",
    "\n",
    "LABEL_TO_CLASS = dict(zip(class_df['class'], class_df['class_name']))\n",
    "CLASS_TO_LABEL = {v: k for k, v in LABEL_TO_CLASS.items()}\n",
    "NUM_CLASSES = len(LABEL_TO_CLASS)\n",
    "\n",
    "img_df = pd.read_csv(IMG_TXT, sep=' ', header=None, names=['img_id', 'img_path'], dtype={'img_id': 'int32'})\n",
    "img_df['img_path'] = img_df['img_path'].apply(lambda x: os.path.join(IMG_DIR, x))\n",
    "\n",
    "split_df = pd.read_csv(SPLIT_TXT, sep=' ', header=None, names=['img_id', 'is_train'], dtype={'img_id': 'int32', 'is_train': 'int32'})\n",
    "\n",
    "label_df = pd.read_csv(LABEL_TXT, sep=' ', header=None, names=['img_id', 'class_id'], dtype={'img_id': 'int32', 'class_id': 'int32'})\n",
    "label_df['class_id'] -= 1\n",
    "\n",
    "bbox_df = pd.read_csv(BBOX_TXT, sep=' ', header=None, names=['img_id', 'x', 'y', 'w', 'h'], dtype={'img_id': 'int32'})\n",
    "bbox_df['bbox'] = bbox_df.apply(lambda r: np.array([r.x, r.y, r.w, r.h], dtype=np.float32), axis=1)\n",
    "bbox_df = bbox_df.drop(columns=['x', 'y', 'w', 'h'])\n",
    "\n",
    "df = img_df.merge(split_df, on='img_id').merge(label_df, on='img_id').merge(bbox_df, on='img_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c13e58",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random flip\n",
    "def random_flip(img, bbox, iw, ih, prob=0.5):\n",
    "    xmin, ymin, xmax, ymax = tf.unstack(bbox)\n",
    "    def do_flip():\n",
    "        img_f = tf.image.flip_left_right(img)\n",
    "        return img_f, tf.stack([iw - xmax, ymin, iw - xmin, ymax])\n",
    "    return tf.cond(tf.random.uniform(()) > prob, do_flip, lambda: (img, bbox))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320eb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotation(img, bbox, iw, ih, max_angle=10.0):\n",
    "    # 1. Define the rotation angle in radians\n",
    "    angle = tf.random.uniform([], -max_angle, max_angle) * math.pi / 180.0\n",
    "    \n",
    "    # 2. Get the transformation matrix for rotation\n",
    "    c_x, c_y = tf.cast(iw, tf.float32) / 2.0, tf.cast(ih, tf.float32) / 2.0\n",
    "    \n",
    "    cos_angle = tf.cos(angle); sin_angle = tf.sin(angle)\n",
    "    \n",
    "    a0 = cos_angle; a1 = -sin_angle; a2 = c_x - a0 * c_x - a1 * c_y\n",
    "    a3 = sin_angle; a4 = cos_angle; a5 = c_y - a3 * c_x - a4 * c_y\n",
    "    transform = [a0, a1, a2, a3, a4, a5, 0.0, 0.0]\n",
    "    \n",
    "    rotated_img = tf.raw_ops.ImageProjectiveTransformV2(\n",
    "        images=tf.expand_dims(img, 0),\n",
    "        transforms=tf.expand_dims(transform, 0),\n",
    "        output_shape=tf.stack([tf.cast(ih, tf.int32), tf.cast(iw, tf.int32)]),\n",
    "        fill_mode=\"REFLECT\", interpolation=\"BILINEAR\"\n",
    "    )\n",
    "    rotated_img = tf.squeeze(rotated_img, 0)\n",
    "    \n",
    "    # 3. Rotate the bounding box\n",
    "    xmin, ymin, xmax, ymax = tf.unstack(bbox)\n",
    "    corners = tf.stack([xmin, ymin, xmax, ymin, xmax, ymax, xmin, ymax])\n",
    "    corners = tf.reshape(corners, [-1, 2])\n",
    "    corners_centered = corners - [c_x, c_y]\n",
    "    \n",
    "    rotated_x = cos_angle * corners_centered[:, 0] - sin_angle * corners_centered[:, 1]\n",
    "    rotated_y = sin_angle * corners_centered[:, 0] + cos_angle * corners_centered[:, 1]\n",
    "    \n",
    "    rotated_corners = tf.stack([rotated_x, rotated_y], axis=1) + [c_x, c_y]\n",
    "    \n",
    "    # The fix: access elements by index instead of unpacking.\n",
    "    min_coords = tf.reduce_min(rotated_corners, axis=0)\n",
    "    max_coords = tf.reduce_max(rotated_corners, axis=0)\n",
    "    \n",
    "    x1_r = min_coords[0]; y1_r = min_coords[1]\n",
    "    x2_r = max_coords[0]; y2_r = max_coords[1]\n",
    "    rotated_bbox = tf.stack([x1_r, y1_r, x2_r, y2_r])\n",
    "    \n",
    "    return rotated_img, rotated_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Scaling\n",
    "def random_scale(img, bbox, iw, ih, low=0.9, high=1.1):\n",
    "    scale = tf.random.uniform((), low, high)\n",
    "    new_h, new_w = tf.cast(ih * scale, tf.float32), tf.cast(iw * scale, tf.float32)\n",
    "\n",
    "    # 1. Resize the image and the bounding box coordinates\n",
    "    img_s = tf.image.resize(img, (new_h, new_w), method='bicubic')\n",
    "    bbox_s = bbox * scale\n",
    "\n",
    "    # 2. Calculate the offset from the crop/pad operation\n",
    "    offset_x = (new_w - iw) // 2\n",
    "    offset_y = (new_h - ih) // 2\n",
    "\n",
    "    img_s = tf.image.resize_with_crop_or_pad(img_s, tf.cast(new_h, tf.int32), tf.cast(new_w, tf.int32))\n",
    "\n",
    "    # 3. Apply the translation\n",
    "    translated_x_min = bbox_s[0] - tf.cast(offset_x, tf.float32)\n",
    "    translated_y_min = bbox_s[1] - tf.cast(offset_y, tf.float32)\n",
    "    translated_x_max = bbox_s[2] - tf.cast(offset_x, tf.float32)\n",
    "    translated_y_max = bbox_s[3] - tf.cast(offset_y, tf.float32)\n",
    "\n",
    "    # 4. Clip and re-normalize the bounding box\n",
    "    clipped_x_min = tf.maximum(0.0, translated_x_min)\n",
    "    clipped_y_min = tf.maximum(0.0, translated_y_min)\n",
    "    clipped_x_max = tf.minimum(tf.cast(iw, tf.float32), translated_x_max)\n",
    "    clipped_y_max = tf.minimum(tf.cast(ih, tf.float32), translated_y_max)\n",
    "\n",
    "    bbox_s = tf.stack([clipped_x_min, clipped_y_min, clipped_x_max, clipped_y_max], axis=-1)\n",
    "\n",
    "    return img_s, bbox_s, new_w, new_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14ad412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_erasing(img, iw, ih, p=0.5, erase_area=0.1):\n",
    "    if tf.random.uniform(()) > p:\n",
    "        area = ih * iw\n",
    "        target = erase_area * area\n",
    "        e_h = e_w = tf.cast(tf.sqrt(target), tf.int32)\n",
    "        iw_int = tf.cast(iw, tf.int32)\n",
    "        ih_int = tf.cast(ih, tf.int32)\n",
    "        x1 = tf.random.uniform((), tf.cast(0, tf.int32), iw_int - e_w, tf.int32)\n",
    "        y1 = tf.random.uniform((), tf.cast(0, tf.int32), ih_int - e_h, tf.int32)\n",
    "\n",
    "        # Create indices for the region to erase\n",
    "        xx, yy = tf.meshgrid(tf.range(x1, x1 + e_w), tf.range(y1, y1 + e_h))\n",
    "        indices = tf.stack([yy, xx], axis=-1)\n",
    "        indices = tf.reshape(indices, [-1, 2])\n",
    "\n",
    "        # Create the tensor of zeros to scatter\n",
    "        updates = tf.zeros((e_h * e_w, tf.shape(img)[-1]), dtype=img.dtype)\n",
    "\n",
    "        # Scatter the zeros into the image\n",
    "        img = tf.tensor_scatter_nd_update(img, indices, updates)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7fda0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(img, label, bbox, iw, ih):\n",
    "    \n",
    "    img, bbox = random_flip(img, bbox, iw, ih, prob=0.5)\n",
    "    img, bbox = random_rotation(img, bbox, iw, ih, max_angle=5.0)\n",
    "    img, bbox, iw, ih = random_scale(img, bbox, iw, ih, low=0.95, high=1.05)\n",
    "\n",
    "    img = random_erasing(img, iw, ih, p=0.5, erase_area=0.05)\n",
    "    img = tf.image.random_brightness(img, 0.05)\n",
    "    img = tf.image.random_contrast(img, 0.95, 1.05)\n",
    "    img = tf.image.random_hue(img, 0.02)\n",
    "    img = tf.image.random_saturation(img, 0.95, 1.05)\n",
    "    return img, label, bbox, iw, ih"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96083618",
   "metadata": {},
   "source": [
    "# Data Loading Pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2da1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipeline\n",
    "def read_point(path, label, bbox):\n",
    "    img = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n",
    "    ih, iw = tf.cast(tf.shape(img)[0], tf.float32), tf.cast(tf.shape(img)[1], tf.float32)\n",
    "    x, y, w, h = tf.unstack(bbox)\n",
    "    return img, label, tf.stack([x, y, x+w, y+h]), iw, ih\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "def normalise(img, label, bbox, iw, ih):\n",
    "    img = tf.image.resize(img, IMG_SIZE[:2], method='bicubic')\n",
    "    img = (img - tf.reduce_min(img)) / (tf.reduce_max(img) - tf.reduce_min(img)) * 255.0\n",
    "    #img = img/127.5 - 1\n",
    "    img = preprocess_input(img)\n",
    "    #img = tf.cast(img, tf.float32)\n",
    "    x1, y1, x2, y2 = tf.unstack(bbox)\n",
    "    return img, (label, tf.stack([x1/iw, y1/ih, x2/iw, y2/ih]))\n",
    "\n",
    "def get_ds(df, batch_size, augment, shuffle):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((df.img_path.values,\n",
    "                                             df.class_id.values,\n",
    "                                             np.stack(df.bbox.to_numpy())))\n",
    "    ds = ds.map(read_point, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if augment: \n",
    "        ds = ds.map(augment_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    if shuffle: ds = ds.shuffle(len(df))\n",
    "    ds = ds.map(normalise, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = get_ds(df[df.is_train==1], BATCH_SIZE, augment=True, shuffle=True)\n",
    "test_ds  = get_ds(df[df.is_train==0], BATCH_SIZE, augment=False, shuffle=False)\n",
    "test_ds_eval = get_ds(df[df.is_train==0], BATCH_SIZE, augment=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8237ba72",
   "metadata": {},
   "source": [
    "# Dataset Visualisation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe72f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def viz_batch(imgs, labels, bboxes, label_map, cols=8):\n",
    "    bs = imgs.shape[0]; rows = math.ceil(bs/cols)\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
    "    axes = axes.flatten()\n",
    "    for i in range(bs):\n",
    "        img = imgs[i]\n",
    "        img = tf.cast(img, tf.uint8)\n",
    "        axes[i].imshow(img); axes[i].axis('off')\n",
    "        x1,y1,x2,y2 = bboxes[i]*IMG_SIZE[0]\n",
    "        rect = patches.Rectangle((x1,y1), x2-x1, y2-y1,\n",
    "                                 linewidth=2, edgecolor='red', facecolor='none')\n",
    "        axes[i].add_patch(rect)\n",
    "        axes[i].text(x1, y1-5, label_map[int(labels[i])],\n",
    "                     color='white', backgroundcolor='red', fontsize=8)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "for imgs, (labels, bboxes) in train_ds.take(1):\n",
    "    viz_batch(imgs.numpy(), labels.numpy(), bboxes.numpy(), LABEL_TO_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40bb8d8",
   "metadata": {},
   "source": [
    "# Loss & Metric\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f365610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom IoU metric & focal-EIoU loss\n",
    "def iou(y_true, y_pred):\n",
    "    x1,y1,x2,y2 = tf.unstack(y_true, axis=-1)\n",
    "    xp1,yp1,xp2,yp2 = tf.unstack(y_pred, axis=-1)\n",
    "    ix1,iy1 = tf.maximum(x1, xp1), tf.maximum(y1, yp1)\n",
    "    ix2,iy2 = tf.minimum(x2, xp2), tf.minimum(y2, yp2)\n",
    "    iw, ih = tf.maximum(0., ix2-ix1), tf.maximum(0., iy2-iy1)\n",
    "    inter = iw*ih\n",
    "    area_t = (x2-x1)*(y2-y1); area_p = (xp2-xp1)*(yp2-yp1)\n",
    "    return inter/(area_t+area_p-inter+1e-8)\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "def focal_eiou(y_true, y_pred, alpha=0.25, gamma=2.0):\n",
    "    iou_score = iou(y_true, y_pred)\n",
    "    huber = losses.Huber()(y_true, y_pred)\n",
    "    focal = alpha * tf.pow(1 - iou_score, gamma)\n",
    "    return focal * (huber + (1 - iou_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98837f72",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976ace13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def feature_extractor(trainable=False):\n",
    "    base = efficientnet_v2.EfficientNetV2S(include_top=False, weights='imagenet', input_shape=IMG_SIZE)\n",
    "    base.trainable = trainable\n",
    "    inp = layers.Input(IMG_SIZE)\n",
    "    return models.Model(inp, base(inp), name='feat_ext')\n",
    "\n",
    "def build_detector():\n",
    "    inp = layers.Input(IMG_SIZE)\n",
    "    feat = feature_extractor(trainable=False)(inp)\n",
    "    x = layers.GlobalAveragePooling2D()(feat)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    cls = layers.Dense(NUM_CLASSES, activation='softmax', name='class_probs')(x)\n",
    "    bbox = layers.Dense(4, activation='sigmoid', name='bbox')(x)\n",
    "    return models.Model(inp, [cls, bbox], name='detector')\n",
    "\n",
    "model = build_detector()\n",
    "lr = 1e-4\n",
    "sched = optimizers.schedules.CosineDecayRestarts(lr, first_decay_steps=5 * 188, t_mul=2.0, m_mul=0.8, alpha=0.1)\n",
    "\n",
    "# Build and compile model\n",
    "opt = optimizers.AdamW(learning_rate=sched, weight_decay=1e-4)\n",
    "model.compile(optimizer=opt, loss={'class_probs': losses.SparseCategoricalCrossentropy(),\n",
    "                                   'bbox': focal_eiou},\n",
    "            loss_weights={'class_probs': 1.0, 'bbox': 2.0},\n",
    "            metrics={'class_probs': [metrics.SparseCategoricalAccuracy(name='accuracy'), \n",
    "                                     metrics.SparseTopKCategoricalAccuracy(k=100, name='top_100')],\n",
    "                      'bbox': [iou]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae392f1c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30d891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with the corrected callback\n",
    "history = model.fit(train_ds, validation_data=test_ds, epochs=EPOCHS,\n",
    "                    callbacks=[callbacks.ModelCheckpoint(f\"best_detector_EfficientNet.keras\", monitor='val_loss', save_best_only=True, verbose=1),\n",
    "                                callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=10, restore_best_weights=True, verbose=1)],\n",
    "                    verbose=1)\n",
    "\n",
    "with open('training_history_EfficientNet.json', 'w') as f:\n",
    "    json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66747487",
   "metadata": {},
   "source": [
    "##### Details\n",
    "- Approx 3:20 min for each epoch.\n",
    "- Max memory comsumption during starting of the epoch (maybe due to large buffersize - around 17 gb). Rapidly decreasing then at validation 5-6 gb.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ef97f",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d263c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "model.load_weights('best_detector_EfficientNet.keras')\n",
    "res = model.evaluate(test_ds_eval, return_dict=True)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4eb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report & mean IoU\n",
    "all_labels, all_preds, all_true, all_pred = [], [], [], []\n",
    "for imgs, (cls_true, bb_true) in test_ds_eval:\n",
    "    cls_pred, bb_pred = model.predict(imgs, verbose=0)\n",
    "    all_labels += cls_true.numpy().tolist()\n",
    "    all_preds  += np.argmax(cls_pred, axis=1).tolist()\n",
    "    all_true   += bb_true.numpy().tolist()\n",
    "    all_pred   += bb_pred.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebda498",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_iou = np.mean([iou(tf.constant(t), tf.constant(p)).numpy()\n",
    "                    for t, p in zip(all_true, all_pred)])\n",
    "print(f\"Mean IoU: {mean_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "def viz_pred(imgs, bb_true, bb_pred, label_true, cls_pred, label_map, cols=8):\n",
    "    label_pred = np.argmax(cls_pred, axis=1); max_prob = np.max(cls_pred, axis=1)\n",
    "    bs = imgs.shape[0]; rows = math.ceil(bs/cols)\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols,4*rows), dpi=1000)\n",
    "    \n",
    "    # Flatten axes if it's a grid; handle single subplot case\n",
    "    if rows == 1 and cols == 1: axes = np.array([axes])\n",
    "    else: axes = axes.flatten()\n",
    "\n",
    "    for i in range(bs):\n",
    "        img = tf.cast(imgs[i], tf.uint8)\n",
    "        axes[i].imshow(img); axes[i].axis('off')\n",
    "        \n",
    "        # ðŸ†• Calculate IoU for the current image's prediction\n",
    "        iou_score = iou(y_true=tf.expand_dims(bb_true[i], axis=0), y_pred=tf.expand_dims(bb_pred[i], axis=0)).numpy().item()\n",
    "\n",
    "        for b, l, col in zip([bb_true[i], bb_pred[i]], [label_true[i], label_pred[i]], ['green','red']):\n",
    "            x1,y1,x2,y2 = b*IMG_SIZE[0]\n",
    "            rect = patches.Rectangle((x1,y1), x2-x1, y2-y1, linewidth=2, edgecolor=col, facecolor='none')\n",
    "            axes[i].add_patch(rect)\n",
    "            if col=='green': axes[i].text(x1, y1-5, f\"GT: {label_map[l]}\", color='white', backgroundcolor=col, fontsize=8)\n",
    "            else: axes[i].text(x1, y2+5, f\"PR: {label_map[l]} ({max_prob[i]*100:.2f}%) \\nIoU:{iou_score:.2f}\", color='white', backgroundcolor=col, fontsize=8)\n",
    "\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "for imgs, (labs, bbs) in test_ds_eval.take(1):\n",
    "    cls_pred, bb_pred = model(imgs)\n",
    "\n",
    "viz_pred(imgs.numpy(), bbs.numpy(), bb_pred, labs.numpy(), cls_pred, LABEL_TO_CLASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d85694",
   "metadata": {},
   "source": [
    "# Plotting History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_history_metrics(history_data):\n",
    "    # Identify the unique metrics (e.g., 'loss', 'bbox_iou', etc.)\n",
    "    all_keys = history_data.keys()\n",
    "    metric_names = sorted([key for key in all_keys if not key.startswith('val_')])\n",
    "\n",
    "    # Determine the number of subplots and grid layout\n",
    "    num_metrics = len(metric_names)\n",
    "    cols = 3  # Plotting three columns for better aspect ratio\n",
    "    rows = (num_metrics + 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 4 * rows), dpi=1000)\n",
    "    # Flatten the axes array for easy iteration, useful for a grid\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, metric in enumerate(metric_names):\n",
    "        ax = axes[i]\n",
    "        val_metric = f'val_{metric}'\n",
    "\n",
    "        # Check if the validation metric exists to avoid errors\n",
    "        if val_metric in history_data:\n",
    "            ax.plot(history_data[metric], label=f'Training {metric}', color='blue')\n",
    "            ax.plot(history_data[val_metric], label=f'Validation {metric}', color='red', linestyle='dashed')\n",
    "            ax.set_title(f'Training vs. Validation {metric.replace(\"_\", \" \").title()}', fontsize=10)\n",
    "            ax.set_xlabel('Epoch', fontsize=10)\n",
    "            ax.set_ylabel(metric.replace(\"_\", \" \").title(), fontsize=10)\n",
    "            ax.legend(fontsize=9)\n",
    "            ax.grid(True)\n",
    "        else:\n",
    "            # Handle cases with no validation metric\n",
    "            ax.plot(history_data[metric], label=f'Training {metric}', color='blue')\n",
    "            ax.set_title(f'Training {metric.replace(\"_\", \" \").title()}', fontsize=10)\n",
    "            ax.set_xlabel('Epoch', fontsize=10)\n",
    "            ax.set_ylabel(metric.replace(\"_\", \" \").title(), fontsize=10)\n",
    "            ax.legend(fontsize=9)\n",
    "            ax.grid(True)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Load the history data from the provided JSON file\n",
    "with open('training_history_EfficientNet.json', 'r') as f:\n",
    "    training_history_data = json.load(f)\n",
    "\n",
    "# Call the function to plot all metrics\n",
    "plot_all_history_metrics(training_history_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a5b09",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ec5c5a",
   "metadata": {},
   "source": [
    "### A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_labels, all_preds,\n",
    "      target_names=[LABEL_TO_CLASS[i] for i in range(NUM_CLASSES)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e282e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
